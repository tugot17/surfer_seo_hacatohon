{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allegro/herbert-base-cased were not used when initializing BertModel: ['cls.sso.sso_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.sso.sso_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import categories\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "THRESHOLD = 100\n",
    "\n",
    "model_names = {\n",
    "    \"herbert-klej-cased-v1\": {\n",
    "        \"tokenizer\": \"allegro/herbert-klej-cased-tokenizer-v1\", \n",
    "        \"model\": \"allegro/herbert-klej-cased-v1\",\n",
    "    },\n",
    "    \"herbert-base-cased\": {\n",
    "        \"tokenizer\": \"allegro/herbert-base-cased\", \n",
    "        \"model\": \"allegro/herbert-base-cased\",\n",
    "    },\n",
    "    \"herbert-large-cased\": {\n",
    "        \"tokenizer\": \"allegro/herbert-large-cased\", \n",
    "        \"model\": \"allegro/herbert-large-cased\",\n",
    "    },\n",
    "}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_names[\"herbert-base-cased\"][\"tokenizer\"])\n",
    "herbert = AutoModel.from_pretrained(model_names[\"herbert-base-cased\"][\"model\"]).to(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def herbert_forward(data, batch_size=256):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(data), batch_size)):\n",
    "        batch = data[i:i+batch_size]\n",
    "        tokens = tokenizer.batch_encode_plus(\n",
    "            batch,\n",
    "            padding=\"longest\",\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            for key in tokens.keys():\n",
    "                tokens[key] = tokens[key].to(device)\n",
    "\n",
    "        embeddings.append(herbert(**tokens)['pooler_output'].cpu())\n",
    "    return torch.cat(embeddings)\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "def train(batch_size=256, validate=False):\n",
    "    places = pd.read_csv('places.csv.gz')\n",
    "    places = places[places['language'] == 'pl'][places['category'].map(places['category'].value_counts()) > THRESHOLD].reset_index()\n",
    "    X = pd.DataFrame(herbert_forward(list(places['query'])).numpy())\n",
    "    X['category'] = places['category'].map(categories.cat_id)\n",
    "    X['audit_latitude'] = places['audit_latitude']\n",
    "    X['audit_longitude'] = places['audit_longitude']\n",
    "    X.fillna(len(categories.id_cat))\n",
    "    y = places['position']\n",
    "    # print(y.isna())\n",
    "    model.fit(X, y)\n",
    "    if validate:\n",
    "        y_pred = model.predict(X)\n",
    "        print(mean_squared_error(y, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\proto\\AppData\\Local\\Temp/ipykernel_7936/3105698679.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  places = places[places['language'] == 'pl'][places['category'].map(places['category'].value_counts()) > THRESHOLD]\n",
      "100%|██████████| 1761/1761 [00:39<00:00, 44.45it/s]\n"
     ]
    }
   ],
   "source": [
    "validate = True\n",
    "columns = ['language', 'category', 'query', 'position', 'audit_latitude', 'audit_longitude']\n",
    "places = pd.read_csv('places.csv.gz')[columns].dropna()\n",
    "places = places[places['language'] == 'pl'][places['category'].map(places['category'].value_counts()) > THRESHOLD].reset_index()\n",
    "y = places['position']\n",
    "X = pd.DataFrame(herbert_forward(list(places['query'])).numpy())\n",
    "X['category'] = places['category'].map(categories.cat_id)\n",
    "X['audit_latitude'] = places['audit_latitude']\n",
    "X['audit_longitude'] = places['audit_longitude']\n",
    "X.fillna(len(categories.id_cat), inplace=True)\n",
    "# print(y.isna())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.91313709764606\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y)\n",
    "if validate:\n",
    "    y_pred = model.predict(X)\n",
    "    print(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     23746\n",
       "2.0     23679\n",
       "3.0     23567\n",
       "4.0     23508\n",
       "5.0     23298\n",
       "6.0     23115\n",
       "7.0     23031\n",
       "8.0     22901\n",
       "9.0     22819\n",
       "10.0    22632\n",
       "11.0    22452\n",
       "12.0    22343\n",
       "13.0    22203\n",
       "14.0    22037\n",
       "15.0    21835\n",
       "16.0    21699\n",
       "17.0    21606\n",
       "18.0    21527\n",
       "19.0    21435\n",
       "20.0    21218\n",
       "Name: position, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560758   NaN\n",
       "560759   NaN\n",
       "560760   NaN\n",
       "560761   NaN\n",
       "560762   NaN\n",
       "          ..\n",
       "902829   NaN\n",
       "902830   NaN\n",
       "902831   NaN\n",
       "902832   NaN\n",
       "902833   NaN\n",
       "Name: position, Length: 315, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[y.isna()]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae9258babb9dc6183a521d7a445c874d7696eb0fb582154c3a2ca8b33699b65d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
